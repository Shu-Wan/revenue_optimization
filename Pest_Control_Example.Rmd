---
title: "Pest Control"
author: "Lauren Kennedy, Jonah Gabry, & Rob Trangucci"
date: "July 23, 2018"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(rstan)
library(dplyr)
library(reshape2)
library(bayesplot)
library(ggplot2)

theme_set(bayesplot::theme_default())
set.seed(1123) # for R's pseudo-RNGs, not Stan's
```

## Problem set-up

LLet's say that you're a data scientist working as an independent contractor. You're contacted by the property manager of a large property network in New York City. They explain that they are having an issue with the number of cockroach complaints that they receive from their buildings. Previously they have offered monthly visits from a pest inspector as a solution to this problem. While this is the default solution of many property managers in NYC, the tennants are rarely home when the inpector visits, and so the manager reasons that this is a relatively expensive solution that is currently not very effective.

One alternative to this problem is to deploy long term bait stations. In this alternative child and pet safe bait stations are installed throughout the apartment building. Cockroaches obtain quick acting poison from these stations distribute it throughout the colony. The manufactorer for these bai stations provides some indication of the space to bait efficacy, but the manager suspects that this guidance was not calculated for NYC roaches. NYC roaches, the manager rationalises, have more hustle than traditional roaches; and NYC buildings are built differently to other common domestic buildings in the US. This is particularly important as the unit cost for each bait station is quite high.

The manager wishes to employ your services to help them to optomize the number of roach bait stations they should place in each of their buildings in order to minimise both the number of cockroach complaints and expenditure on pest control. They have randomly selected `r N_buildings` buildings. At the beginning of each month, a pest inspector randomly places a number of bait stations throughout the building, without knowledge of the current cockroach levels in the building. At the end of the month, the manager records the total number of cockroach complaints in that building. The manager would like to predict the optimise number of traps ($t$) and complaints ($c$) for these `r N_buildings` 10 buildings, and predict for new buildings how many bait stations they should place. 

\begin{align*}
\arg\min_{t \in T} \mathbb{E}_c[c(t) \, t]
\end{align*}

As the property manager has complete control over the number of traps set, the random variable contributing to this expectation is the number of complaints given the number of traps. We will model the number of complaints as a function of the number of traps. 

The data is in a file called $\texttt{building_data_20180723.RDS}$. Let's load the data and see what the structure
is:

```{r load-data}
pest_data <- readRDS('data/building_data_20180723.RDS')
head(pest_data)
```


```{r describe-data}
N_buildings <- length(unique(pest_data$building_id))
N_buildings
```

We're working with `r N_buildings` buildings. We should first want to learn whether the number of complaints is
related to number of cockroach traps. 

How can we model the number of complaints? We already know some rudimentary information about what we should expect. The number of complaints over a month should be either zero or an integer. The property manager tells us that it is possible but unlikely that number of complaints in a given month is zero. Occasionally there are a very large number of complaints in a single month. A common way of modelling this sort of skewed, single bounded count data is as a Poisson random variable. In this case we can see that our outcome variable is overdispersed - that is, the variance is larger than the mean - so we will model this using a negative binomial random variable instead. 

We will start with a simple model and build it up slowly. First, we'll define our 
likelihood to be the negative binomial probability mass function over the number
of traps placed in the building, denoted below as $\texttt{n_complaints}$.

\begin{align*}
\texttt{n_complaints}_{m,t} & \sim \text{Neg-Binomial-log}(\eta_{m,t}, \phi) \\
\eta_{m,t} & = \alpha + \beta \, p_{m,t}
\end{align*}

The negative binomial mass function we'll use is called 
$\texttt{neg_binomial_2_log}(\text{ints} \, y, \text{reals} \, \eta, \text{reals} \, \phi)$ in Stan.
This is negative binomial mass function that is parameterized in terms of its 
log-mean, $\eta$, and its precision $\phi$. This means that $\mathbb{E}[y] \, = exp(\eta)$ 
and $\text{Var}[y] = \exp(\eta) + \exp(\eta)^2 / \phi$. 

We can use this distribution for our outcome, n_complaints, because we have integer 
outcomes (number of movies sold per week). However, this isn't a good enough 
reason to use the negative binomial distribution. We could use a Poisson
distribution. However, the Poisson distribution has only one parameter, which requires
that the mean of the Poisson random variable be equal to the variance of the random
variable. However, our data appear to be overdispersed. We can check this by
taking the mean of qty_sld for each movie and comparing it to the variance of
qty_sld of each movie. We want to do this check because we would assume that if
the data were generated by a Poisson distribution, each movie would have a
variance roughly equal to its mean. We probably wouldn't expect this to hold
across movies because different movies likely have different average sales per
week.

Let's prep the data. First, because we're concerned about comparing our
predictions for certain products, and we'd like to do the comparison in Stan, we
should convert our titles to integers.

```{r prep-data}
N_months <- max(table(pest_data$building_id))
pest_data <- pest_data %>%
  mutate(building_fac = as.factor(building_id),
         building_idx = as.integer(building_fac),
         ids = rep(1:N_months, N_buildings),
         mo_idx = lubridate::month(date))
building_data <- unique(pest_data[,c('building_idx','live_in_super', 'age_of_building', 'total_sq_foot',
                               'average_tenant_age', 'monthly_average_rent',
                               'floors')]) %>%
  arrange(building_idx) %>% select(-building_idx) %>% as.matrix()
```

We create the list to pass into RStan as data. We'll be thorough and include everything
we think we'll use in a model.

```{r stan-data}
stan_dat_simple <- list(
  N = nrow(pest_data), 
  complaints = pest_data$complaints,
  traps = pest_data$traps
)
```

Before we fit the first model we defined above, let's generate some fake data against which to
test our Stan program. If we are able to recover known parameter values, it is a good indication
that our Stan program is working.

Let's compile the fake data generating code in the file simple_NB_poisson_dgp.stan.

```{r compNBdgp, cache=T, results="hide", message=FALSE}
comp_dgp_simple <- stan_model('stan_programs/simple_poisson_regression_dgp.stan')
```


```{r runpoissondgp}
fitted_model_dgp <- sampling(
  comp_dgp_simple,
  data = list(N = nrow(pest_data), mean_traps = mean(pest_data$traps)),
  chains = 1,
  iter = 1,
  algorithm = 'Fixed_param',
  seed = 123
  )
samps_dgp <- rstan::extract(fitted_model_dgp)
str(samps_dgp)
```


```{r P_fake_stan_dat}
stan_dat_fake <- list(
  N = nrow(pest_data), 
  traps = samps_dgp$traps[1, ], 
  complaints = samps_dgp$complaints[1, ]
)
str(stan_dat_fake)
```

```{r compNB, cache=T, results="hide", message=FALSE}
comp_model_P <- stan_model('stan_programs/simple_poisson_regression.stan')
```

```{r runPoverfake}
fit_model_P <- sampling(comp_model_P, data = stan_dat_fake)
posterior_alpha_beta <- as.matrix(fit_model_P, pars = c('alpha','beta'))
head(posterior_alpha_beta)
```

```{r}
true_alpha_beta <- c(samps_dgp$alpha, samps_dgp$beta)
mcmc_recover_hist(posterior_alpha_beta, true = true_alpha_beta)
```

```{r marginal_PPC}
y_rep <- as.matrix(fit_model_P, pars = "y_rep")
mean_y_rep <- colMeans(y_rep)
std_resid <- (stan_dat_fake$complaints - mean_y_rep) / sqrt(mean_y_rep)
qplot(mean_y_rep, std_resid) + hline_at(1) + hline_at(-1)
```

```{r}
ppc_rootogram(stan_dat_fake$complaints, yrep = y_rep)
```


```{r fit_P_real_data, cache=T}
fit_P_real_data <- sampling(comp_model_P, data = stan_dat_simple, chains = 4, cores =4 )
```

```{r results_simple_P}
print(fit_P_real_data, pars = c('alpha','beta'))
```

Ok price is related to quantity sold, so let's see how well the model fits.

```{r marginal_PPC}
y_rep <- as.matrix(fit_P_real_data, pars = "y_rep")
bayesplot::ppc_dens_overlay(stan_dat_simple$complaints, y_rep[1:200,])
```

```{r marginal_PPC}
mean_y_rep <- colMeans(y_rep)
std_resid <- (stan_dat_simple$complaints - mean_y_rep) / sqrt(mean_y_rep)
qplot(mean_y_rep, std_resid) + hline_at(1) + hline_at(-1)
```

```{r}
ppc_rootogram(stan_dat_simple$complaints, yrep = y_rep)
```

Maybe there're some good information that we're not using, like the
square footage of the building?

```{r}
sq_foot_dat_lm <- lm(log1p(complaints) ~ total_sq_foot, data = pest_data)
with(pest_data, plot(total_sq_foot, log1p(complaints)))
abline(reg = sq_foot_dat_lm)
```

```{r}
stan_dat_simple$sq_foot <- log(pest_data$total_sq_foot/1e4)
stan_dat_simple$live_in_super <- pest_data$live_in_super
```

```{r}
stan_dat_fake$sq_foot <- rnorm(stan_dat_fake$N)
stan_dat_fake$live_in_super <- rnorm(stan_dat_fake$N)
```

```{r compmultPDGP, cache=T, results="hide", message=FALSE}
comp_dgp_multiple <- stan_model('stan_programs/multiple_poisson_regression_dgp.stan')
```

```{r runpoissondgp}
fitted_model_dgp <- sampling(comp_dgp_multiple, data = stan_dat_fake, chains = 1, cores = 1, iter = 1, algorithm='Fixed_param', seed=123)
samps_dgp <- rstan::extract(fitted_model_dgp)
```

```{r P_fake_stan_dat}
stan_dat_fake$complaints <- samps_dgp$y_gen[1,]
```

```{r compNB, cache=T, results="hide", message=FALSE}
comp_model_P_mult <- stan_model('stan_programs/multiple_poisson_regression.stan')
```

```{r runPoverfake}
fit_model_P_mult <- sampling(comp_model_P_mult, data = stan_dat_fake, chains = 4, cores = 4)
samps_pars <- as.matrix(fit_model_P_mult, pars = c('alpha','beta','beta_super','beta_sq_foot'))
```

```{r}
bayesplot::mcmc_recover_intervals(samps_pars,
                             c(samps_dgp$alpha,samps_dgp$beta,samps_dgp$beta_super,samps_dgp$beta_sq_foot))
```

Now let's fit to real data.

[Note to Jonah: If we don't rescale the predictors, we get a bunch of max treedepth warnings, because our
priors aren't well matched to the scale of the data. I know this is something you like to talk about, so
we can do that here, but I didn't broach it because it'll take some work to build a model that fits poorly
but not egregiously so, in order to not get treedepth warnings]

```{r fit_mult_P_real_dat}
stan_dat_simple$live_in_super <- scale(stan_dat_simple$live_in_super)[,1]
fit_model_P_mult_real <- sampling(comp_model_P_mult, data = stan_dat_simple, cores = 4, chains = 4)
```

```{r marginal_PPC}
samps_P_real_data <- rstan::extract(fit_model_P_mult_real)
bayesplot::ppc_dens_overlay(stan_dat_simple$complaints, 
                          samps_P_real_data$pp_y[1:200,])
```

```{r marginal_PPC}
y_rep <- samps_P_real_data$pp_y
mean_y_rep <- colMeans(y_rep)
std_resid <- (stan_dat_simple$complaints - mean_y_rep) / sqrt(mean_y_rep)
plot(mean_y_rep, std_resid)
abline(h=1)
abline(h=-1)
```

```{r}
ppc_rootogram(stan_dat_simple$complaints, yrep = y_rep)
```

We'll start with a simple model and build it up slowly. First, we'll define our 
likelihood to be the negative binomial probability mass function over the number
of units sold, denoted below as $\texttt{qty_sld}$.

\begin{align*}
\texttt{qty_sld}_{m,t} & \sim \text{Neg-Binomial-log}(\eta_{m,t}, \phi) \\
\eta_{m,t} & = \alpha + \beta \, p_{m,t}
\end{align*}

The negative binomial mass function we'll use is called 
$\texttt{neg_binomial_2_log}(\text{ints} \, y, \text{reals} \, \eta, \text{reals} \, \phi)$ in Stan.
This is negative binomial mass function that is parameterized in terms of its 
log-mean, $\eta$, and its precision $\phi$. This means that $\mathbb{E}[y] \, = exp(\eta)$ 
and $\text{Var}[y] = \exp(\eta) + \exp(\eta)^2 / \phi$. 

We can use this distribution for our outcome, qty_sld, because we have integer 
outcomes (number of movies sold per week). However, this isn't a good enough 
reason to use the negative binomial distribution. We could use a Poisson
distribution. However, the Poisson distribution has only one parameter, which requires
that the mean of the Poisson random variable be equal to the variance of the random
variable. However, our data appear to be overdispersed. We can check this by
taking the mean of qty_sld for each movie and comparing it to the variance of
qty_sld of each movie. We want to do this check because we would assume that if
the data were generated by a Poisson distribution, each movie would have a
variance roughly equal to its mean. We probably wouldn't expect this to hold
across movies because different movies likely have different average sales per
week.

```{r compNBdgp, cache=T, results="hide", message=FALSE}
comp_dgp_mult_NB <- stan_model('stan_programs/multiple_NB_regression_dgp.stan')
```

We're going to generate one draw from the fake data model so we can use the data to fit our
model and compare the known values of the parameters to the posterior density of the parameters.

```{r runNBdgp}
fitted_model_dgp <- sampling(comp_dgp_mult_NB, data = stan_dat_fake, chains = 1, cores = 1, iter = 1, algorithm='Fixed_param',seed=1796604581)
samps_dgp <- rstan::extract(fitted_model_dgp)
```

We create a new dataset with the fake outcome data replacing the true observed outcomes.

```{r fake_stan_dat}
stan_dat_fake$complaints <- samps_dgp$y_gen[1,]
```

```{r compNB, cache=T, results="hide", message=FALSE}
comp_model_NB <- stan_model('stan_programs/multiple_NB_regression.stan')
```

Now we run our NB regression over the fake data and extract the samples to 
examine posterior predictive checks and to check whether we've sufficiently
recovered our known parameters, $\texttt{alpha}$ $\texttt{beta}$.

```{r runNBoverfake}
fitted_model_NB <- sampling(comp_model_NB, data = stan_dat_fake, chains = 4, cores = 4)
samps_NB <- rstan::extract(fitted_model_NB)
samps_pars <- as.matrix(fitted_model_NB, pars = c('alpha','beta','beta_super','beta_sq_foot','inv_prec'))
```

```{r}
bayesplot::mcmc_recover_intervals(samps_pars, 
                              c(samps_dgp$alpha,
                                samps_dgp$beta,
                                samps_dgp$beta_super,samps_dgp$beta_sq_foot,samps_dgp$inv_prec))
```

The parameter recovery looks good. Let's run the model over the real data and see
how our model fares!

```{r runNB}
fitted_model_NB <- sampling(comp_model_NB, data = stan_dat_simple, chains = 4, cores = 4)
samps_NB <- rstan::extract(fitted_model_NB)
```

Let's look at our predictions vs. the data.

```{r ppc-full}
bayesplot::ppc_dens_overlay(stan_dat_simple$complaints, 
                            samps_NB$pp_y[1:200,])
```

```{r marginal_PPC}
y_rep <- samps_P_real_data$pp_y
mean_y_rep <- colMeans(y_rep)
std_resid <- (stan_dat_simple$complaints - mean_y_rep) / sqrt(mean_y_rep + mean_y_rep^2*mean(samps_NB$inv_prec))
plot(mean_y_rep, std_resid)
abline(h=1)
abline(h=-1)
```

```{r}
ppc_rootogram(stan_dat_simple$complaints, yrep = y_rep)
```

It appears that our data generating process that we've encoded in our model doesn't match the
data we've been given. We're over-estimating the tails of the data and under-estimating the
small counts. Are there other statistics we can look at to determine what's missing
from the model?

We can look at the distribution of the means vs. our observed means by movie to
see whether we're at least modeling the means well at the movie level.

```{r ppc-group_means}
groups <- 1:N_buildings
stan_dat_simple$building_idx <- pest_data$building_id
sel_vec <- stan_dat_simple$building_idx %in% groups
bayesplot::ppc_stat_grouped(stan_dat_simple$complaints[sel_vec], 
                            samps_NB$pp_y[1:200,sel_vec], group = stan_dat_simple$building_idx[sel_vec], stat = 'mean')
```


It appears that we aren't modeling the means well for each movie. Let's add a hierarchical
intercept parameter, $\alpha_m$ at the movie level to our model. 

$$
\texttt{qty_sld}_{m,t} \sim \text{Neg-Binomial-log}(\eta_{m,t}, \phi) \\
\eta_{m,t} = \alpha_m + \beta \, p_{m,t} + \beta_{\texttt{rel_year}} \, \texttt{rel_year}_{m} \\
\alpha_m \sim \text{Normal}(\alpha, \sigma_{\alpha})
$$

In our stan model, $\alpha_m$ is the $m$-th element of the vector
$\texttt{alpha}$ defined in the parameter vector. We've dropped the 
rating from the regression. Let's put the release year into the 
hierarchical model for the movie-level intercept.

$$
\alpha_m \sim \text{Normal}(\alpha + \beta_{\texttt{rel_year}} \, \texttt{rel_year}_{m}, \sigma_{\alpha})
$$


```{r stan-data}
stan_dat_hier <- with(pest_data, list(complaints = complaints,
                                       traps = traps,
                                       N = length(traps),
                                       J = N_buildings,
                                       t = N_months,
                                       sq_foot = log(total_sq_foot/1e4),
                                       building_data = scale(building_data[,c('live_in_super',
                                                                'age_of_building',
                                                                'average_tenant_age',
                                                                'monthly_average_rent')]),
                                      K = 4,
                                       building_idx = building_id))
```

```{r comp-NB-hier, cache=T, results="hide", message=FALSE}
comp_model_NB_hier <- stan_model('stan_programs/hier_NB_regression.stan')
```

[Jonah, the doc is good up until here, working on hierarchical NB models now]

```{r run-NB-hier}
fitted_model_NB_hier <- sampling(comp_model_NB_hier, data = stan_dat_hier, chains = 4, cores = 4)
```

```{r} 
samps_hier_NB <- rstan::extract(fitted_model_NB_hier)
```

Let's examine the fit of the new model. 

```{r print-NB-hier}
print(fitted_model_NB_hier, pars = c('sigma_alpha','beta','alpha','prec','alphas'))
```

The effective samples are quite low for many of the parameters. This indicates
that there are problems with our parameterization of the model. We can reparameterize
the random intercept $\alpha_m$, which is distributed:

\begin{align*}
\alpha_m & \sim \text{Normal}(\alpha, \sigma_{\alpha})
\end{align*}

```{r}
bayesplot::mcmc_trace(as.array(fitted_model_NB_hier,pars = 'sigma_alpha'), 
                      np = nuts_params(fitted_model_NB_hier))
```

```{r}
mcmc_scatter(
  as.array(fitted_model_NB_hier),
  pars = c("alphas[4]", 'sigma_alpha'), 
  transform = list('sigma_alpha' = "log"), 
  np = nuts_params(fitted_model_NB_hier)
)
```

```{r}
mcmc_parcoord(
  as.array(fitted_model_NB_hier, pars = c("sigma_alpha", "alphas")),
  np = nuts_params(fitted_model_NB_hier)
)
```

Instead, we should use the non-centered parameterization for $\alpha_m$. We
define a vector of auxiliary variables in the parameters block,
$\texttt{alphas_raw}$ that is given a $\text{Normal}(0, 1)$ prior in the model
block. We then make $\texttt{alphas}$ a transformed parameter:

$$
\begin{verbatim}
transformed parameters {
  vector[J] alphas;
  alphas = alpha + sigma_alpha * alphas_raw;
}
\end{verbatim}
$$

This gives $\texttt{alphas}$ a $\text{Normal}(\alpha, \sigma_\alpha)$ distribution, but it
decouples the dependence of the density of each element of $\texttt{alphas}$ from 
$\texttt{sigma_alpha}$ ($\sigma_\alpha$). hier_NB_regression_ncp.stan uses the non-centered
parameterization for $\texttt{alphas}$. We will examine the effective sample size of the
fitted model to see whether we've fixed the problem with our reparameterization.

```{r comp-NB-hier-ncp}
comp_model_NB_hier_ncp <- stan_model('stan_programs/hier_NB_regression_ncp.stan')
```

```{r run-NB-hier-ncp}
fitted_model_NB_hier_ncp <- sampling(comp_model_NB_hier_ncp, data = stan_dat_hier, chains = 4, cores = 4)
fitted_model_NB_hier_ncp <- sampling(comp_model_NB_hier_ncp, data = stan_dat_hier, chains = 4, cores = 4, 
                                     control = list(adapt_delta=0.9))
```

Examining the fit of the new model

```{r n-eff-NB-hier-ncp-check}
print(fitted_model_NB_hier_ncp, pars = c('sigma_alpha','beta','alpha','prec','alphas'))
```

This seems to have improved the effective sample sizes of $\texttt{alphas}$, though it has
decreased the effective sample size of $\texttt{sigma_alpha}$. We'll stick with the 
non-centered parameterization as long as it appears feasible when we examine our model
diagnostics.

```{r samps-full-hier}
samps_NB_hier_ncp <- rstan::extract(fitted_model_NB_hier_ncp, pars = c('pp_y','inv_prec'))
```

Extracting the draws from the model allows us to see how we've fitted the marginal
distribution of the data with draws from the marginal posterior predictive distribution.
That plot is below.

```{r ppc-full-hier}
bayesplot::ppc_dens_overlay(stan_dat_simple$complaints, 
                          samps_NB_hier_ncp$pp_y[1:200,])
```

This looks quite nice. If we've captured the movie-level means well, then the
posterior distribution of means by movie should match well with the observed
means of the quantity of movie sales by week.

```{r ppc-group_means-hier}
bayesplot::ppc_stat_grouped(stan_dat_simple$complaints, 
                            samps_NB_hier_ncp$pp_y[1:200,], group = stan_dat_simple$building_idx, stat = 'mean')
```


```{r}
y_rep <- samps_NB_hier_ncp$pp_y
mean_y_rep <- colMeans(y_rep)
std_resid <- (stan_dat_hier$complaints - mean_y_rep) / sqrt(mean_y_rep + mean_y_rep^2*mean(samps_NB_hier_ncp$inv_prec))
plot(mean_y_rep, std_resid)
abline(h=1)
abline(h=-1)
```

```{r}
ppc_rootogram(stan_dat_hier$complaints, yrep = y_rep)
```


Ok, so these plots look \emph{much} better. Perhaps if the level of movie sales differs
by movie, the coefficient for price does too. We can add this to our model and observe the
fit.

\begin{align*}
\text{qty_sld}_{m,t} & \sim \text{Neg-Binomial-log}(\eta_{m,t}, \phi) \\
\eta_{m,t} & = \alpha_m + \beta_m \, p_{m,t} \\
\alpha_m & \sim \text{Normal}(\alpha, \sigma_{\alpha}) \\
\beta_m & \sim \text{Normal}(\beta, \sigma_{\beta})
\end{align*}

```{r comp-NB-hier-slopes, cache=T, results="hide", message=FALSE}
comp_model_NB_hier_slopes <- stan_model('hier_slopes_NB_regression_ncp.stan')
```

```{r run-NB-hier-slopes}
fitted_model_NB_hier_slopes <- sampling(comp_model_NB_hier_slopes, data = stan_dat_simple, chains = 4, cores = 4)
samps_NB_hier_slopes <- rstan::extract(fitted_model_NB_hier_slopes, pars = c('sigma_beta',
                                                                              'pp_y'))
```

To see if the model infers movie-to-movie differences in , we can plot a histogram of our marginal
posterior distribution for $\texttt{sigma_beta}$. 

```{r}
hist(samps_NB_hier_slopes$sigma_beta,breaks=50)
```

While the model can't specifically rule out zero from the posterior, it does have mass at small
non-zero numbers, so we should leave in the hierarchy over $\texttt{betas}$. Plotting the marginal
data density again, we can see the model still looks well calibrated.

```{r ppc-full-hier-slopes}
bayesplot::ppc_dens_overlay(stan_dat_simple$qty_sld, 
                            samps_NB_hier_slopes$pp_y[1:200,]) + xlim(c(0,100))
```

Perhaps we add monthly random intercepts to our model. Let's look at the data to see if this
is warranted.

```{r ppc-group_max-hier-slopes-mean-by-mo}
bayesplot::ppc_stat_grouped(stan_dat_simple$qty_sld, 
                            samps_NB_hier_slopes$pp_y[1:200,], group = stan_dat_simple$mo_idx, stat = 'mean')
```

We might be missing information in month indicators. It makes sense, when it gets colder
out there might be more of an incentive to watch movies (at least in the Northeast).

```{r comp-NB-hier-mos, cache=T, results="hide", message=FALSE}
comp_model_NB_hier_mos <- stan_model('hier_slopes_NB_regression_mos.stan')
```

```{r run-NB-hier-slopes-mos}
fitted_model_NB_hier_mos <- sampling(comp_model_NB_hier_mos, data = stan_dat_simple, chains = 4, cores = 4)
```

We get divergent transitions in our run. Let's reparameterize our prior on the $\texttt{mos}$ random
intercept to be a centered hierarchical normal. We only observed divergent transitions after
running the model with monthly random effect

```{r comp-NB-hier-mos-cp, cache=T, results="hide", message=FALSE}
comp_model_NB_hier_mos_cp <- stan_model('hier_slopes_NB_regression_mos_cp.stan')
```
`
```{r run-NB-hier-slopes-mos-cp, cache=TRUE}
fitted_model_NB_hier_mos_cp <- sampling(comp_model_NB_hier_mos_cp, data = stan_dat_simple, chains = 4, cores = 4, control = list(adapt_delta=0.80))
saveRDS(fitted_model_NB_hier_mos_cp,file = 'fitted_model_NB_hier_mos_cp.RDS')
samps_NB_hier_mos_cp <- rstan::extract(fitted_model_NB_hier_mos_cp, pars = c('pp_y'))
```

Note that in order to get this model to fit without divergent transitions we need to crank up
$\texttt{adapt_delta}$ from 0.8 (its default) to 0.99. This may indicate that our model may not
fit our data very well. How might you go about expanding the model? What are observable summary
statistics of the outcome measure, $\texttt{qty_sld}$ that would help you build additional
structure into the priors for our model? 

In the interest of brevity, we won't go on expanding the model. 

```{r ppc-full-hier-mos}
bayesplot::ppc_dens_overlay(stan_dat_simple$qty_sld, 
                            samps_NB_hier_mos_cp$pp_y[1:200,]) + xlim(c(0,100))
```

```{r}
bayesplot::ppc_stat_grouped(stan_dat_simple$qty_sld, 
                            samps_NB_hier_mos_cp$pp_y[1:200,], group = stan_dat_simple$mo_idx, stat = 'mean')
```

As we can see, it appears that our monthly random intercept has captured a monthly
pattern across all the movies.

## Revenue forecasts

Let's modify the Stan program to generate revenue forecasts at different prices in the
last week of data.

We want to predict quantity at each price, and then calculate revenue for each price.

```{r comp-rev, cache=T, results="hide", message=FALSE}
comp_rev <- stan_model('hier_slopes_NB_regression_mos_predict.stan')
```

```{r run-NB-hier-rev, cache=TRUE}
rev_model <- sampling(comp_rev, data = stan_dat_simple, chains = 4, cores = 4, iter = 2000,
                      control = list(adapt_delta = 0.90))
samps_rev <- rstan::extract(rev_model)
```

Below we've generated our revenue curves for the first 10 products. These charts will give us 
precise quantification of our uncertainty around our revenue projections at any price for
each product. This is immensely useful as a decision maker when choosing how to set prices
for these products.

```{r rev-curves}
N_price <- 20
movie_map <- unique(movie_data[,c('title','ttl_idx')])
mean_rev <- apply(samps_rev$hypo_rev,c(2,3),mean)
lower_rev <- apply(samps_rev$hypo_rev,c(2,3),quantile,0.25)
upper_rev <- apply(samps_rev$hypo_rev,c(2,3),quantile,0.75)
mean_qty <- apply(samps_rev$hypo_qty_sld,c(2,3),mean)
lower_qty <- apply(samps_rev$hypo_qty_sld,c(2,3),quantile,0.25)
upper_qty <- apply(samps_rev$hypo_qty_sld,c(2,3),quantile,0.75)
rev_df <- data.frame(rev = as.vector(t(mean_rev)), lower = as.vector(t(lower_rev)),
                     upper = as.vector(t(upper_rev)),
                     price = rep(1:N_price,N_titles),
                     ttl_idx = as.vector(sapply(1:N_titles,rep,N_price)),
                     qty = as.vector(t(mean_qty)),
                     lower_qty = as.vector(t(lower_qty)),
                     upper_qty = as.vector(t(upper_qty)))
rev_df <- rev_df %>% left_join(movie_map, by = 'ttl_idx')
betas <- order(colMeans(samps_rev$betas))[c(1:5, (N_titles - 4):N_titles)]
sub_df <- rev_df %>% filter(ttl_idx %in% betas)
ggplot(data = sub_df, aes(x = price, y = rev)) +
  geom_ribbon(aes(ymin = lower, ymax = upper), fill="grey70") + geom_line() +
  facet_wrap(~ title, scales = 'free_y')
```

Perhaps we'd also like to see the demand curves for each product. Below we've 
plotted the demand curves for the same products.

```{r}
ggplot(data = sub_df, aes(x = price, y = qty)) +
  geom_ribbon(aes(ymin = lower_qty, ymax = upper_qty), fill="grey70") + geom_line() +
  facet_wrap(~ title, scales = 'free_y')
```

Left as an exercise for the reader: 

Let's say our utility function is revenue. If we wanted to maximize expected revenue, we can 
take expectations at each price for each product, and choose the price that maximizes expected
revenue. This will be called a maximum revenue strategy.

How can we generate the distribution of portfolio revenue (i.e. the sum of 
revenue across all the movies) under the maximum revenue strategy from the
posterior draws of $\texttt{hypo_rev}$ we already have from
$\texttt{samps_rev}$?

## Conclusion

We've walked through a full decision analysis problem with Stan. You should have a better
sense how to build hierarchical generalized linear models in Stan, and then how to use the
output to make decisions under uncertainty.  
